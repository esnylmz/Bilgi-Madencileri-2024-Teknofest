{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2fa5a12614de4ad8a081cb4a1e4d0c86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c0a28b0a2f2a4dfbbdadbd1cabbf33f6",
              "IPY_MODEL_1acd101cc2fd46748172b8071f715356",
              "IPY_MODEL_afcabd683b9d4f77a0ae1f8157cd5b7d"
            ],
            "layout": "IPY_MODEL_6bde2b5e1c784e91987ba9674e357946"
          }
        },
        "c0a28b0a2f2a4dfbbdadbd1cabbf33f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_102cd98a8a964c19aa3ec141521cf84b",
            "placeholder": "​",
            "style": "IPY_MODEL_85719c1193924a2d972a5bf943de43f4",
            "value": "Map: 100%"
          }
        },
        "1acd101cc2fd46748172b8071f715356": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95eeddf2c1ac465e83606d8728309205",
            "max": 1220,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_30b544117f6248cda997bd577d16de97",
            "value": 1220
          }
        },
        "afcabd683b9d4f77a0ae1f8157cd5b7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9d3c05a67db4d058db153c1e804218b",
            "placeholder": "​",
            "style": "IPY_MODEL_adbfdfcb30294fee8b2a765a024ca952",
            "value": " 1220/1220 [00:00&lt;00:00, 6913.32 examples/s]"
          }
        },
        "6bde2b5e1c784e91987ba9674e357946": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "102cd98a8a964c19aa3ec141521cf84b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85719c1193924a2d972a5bf943de43f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95eeddf2c1ac465e83606d8728309205": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30b544117f6248cda997bd577d16de97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c9d3c05a67db4d058db153c1e804218b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adbfdfcb30294fee8b2a765a024ca952": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d61bd7ffa5b14486aa1fa4220cc69d3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1ba463bf8d9a46ce95fb04cfae9ba31d",
              "IPY_MODEL_9449ec15fcea4a139dc51a77f0c313f3",
              "IPY_MODEL_00cbba8bb5ab4edaab14dab239d4fbf5"
            ],
            "layout": "IPY_MODEL_abb7014193704f12aac6825f56a352d3"
          }
        },
        "1ba463bf8d9a46ce95fb04cfae9ba31d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_393efa2bd4b8425ca0c5f3c2f4f548c3",
            "placeholder": "​",
            "style": "IPY_MODEL_c36c106ed2504ec789f320bde7153fa7",
            "value": "Map: 100%"
          }
        },
        "9449ec15fcea4a139dc51a77f0c313f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0dddb8e6930f473daae0b39f25bfd03a",
            "max": 976,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6aee9e54b21f43089ba94966ae949f1a",
            "value": 976
          }
        },
        "00cbba8bb5ab4edaab14dab239d4fbf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48c7b2a7155a47299f963d40fe6ea7ab",
            "placeholder": "​",
            "style": "IPY_MODEL_bc2b41d8c63d42339d0aff8a52f6c970",
            "value": " 976/976 [00:02&lt;00:00, 357.88 examples/s]"
          }
        },
        "abb7014193704f12aac6825f56a352d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "393efa2bd4b8425ca0c5f3c2f4f548c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c36c106ed2504ec789f320bde7153fa7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0dddb8e6930f473daae0b39f25bfd03a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6aee9e54b21f43089ba94966ae949f1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "48c7b2a7155a47299f963d40fe6ea7ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc2b41d8c63d42339d0aff8a52f6c970": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "399897962391495c9b5c239387c769f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0c9010f38b934d93a47a54866e99ea07",
              "IPY_MODEL_7a46c99f850f43cb9ed017f902f29faf",
              "IPY_MODEL_d0ecd4c9ee844bf6955f12a17d972702"
            ],
            "layout": "IPY_MODEL_db3ea6aadfa44c76a614c79bdba0f28d"
          }
        },
        "0c9010f38b934d93a47a54866e99ea07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37e9dbeaf7a84b9e806715bf0f026ea3",
            "placeholder": "​",
            "style": "IPY_MODEL_97f60754e5f24d40a07a2bf3ed5fd913",
            "value": "Map: 100%"
          }
        },
        "7a46c99f850f43cb9ed017f902f29faf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ffd8b37d28649e6a14abc80e797755d",
            "max": 244,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_79fe4fd87c6d4596889a53570f407375",
            "value": 244
          }
        },
        "d0ecd4c9ee844bf6955f12a17d972702": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6a707749c8e42b7a49ee58aa39caca0",
            "placeholder": "​",
            "style": "IPY_MODEL_23af7964473f435fb20fd6e35d59794c",
            "value": " 244/244 [00:00&lt;00:00, 834.25 examples/s]"
          }
        },
        "db3ea6aadfa44c76a614c79bdba0f28d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37e9dbeaf7a84b9e806715bf0f026ea3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97f60754e5f24d40a07a2bf3ed5fd913": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ffd8b37d28649e6a14abc80e797755d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79fe4fd87c6d4596889a53570f407375": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b6a707749c8e42b7a49ee58aa39caca0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23af7964473f435fb20fd6e35d59794c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBq86dOQisOM",
        "outputId": "3d7ec3ca-bf16-4f93-b8d2-79dbc402f28b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.20.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.5)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Collecting pyarrow>=15.0.0 (from datasets)\n",
            "  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.5.0,>=2023.1.0 (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.5.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.3.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.7.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Downloading datasets-2.20.0-py3-none-any.whl (547 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.5.0-py3-none-any.whl (316 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.1/316.1 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, pyarrow, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.6.1\n",
            "    Uninstalling fsspec-2024.6.1:\n",
            "      Successfully uninstalled fsspec-2024.6.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.3.1+cu121 requires nvidia-cublas-cu12==12.1.3.1; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cuda-cupti-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cuda-nvrtc-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cuda-runtime-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cudnn-cu12==8.9.2.26; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cufft-cu12==11.0.2.54; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-curand-cu12==10.3.2.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cusolver-cu12==11.4.5.107; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cusparse-cu12==12.1.0.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-nccl-cu12==2.20.5; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-nvtx-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n",
            "gcsfs 2024.6.1 requires fsspec==2024.6.1, but you have fsspec 2024.5.0 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-2.20.0 dill-0.3.8 fsspec-2024.5.0 multiprocess-0.70.16 pyarrow-17.0.0 xxhash-3.4.1\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset"
      ],
      "metadata": {
        "id": "FkC4Ov1yi-f4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datasets import Dataset, DatasetDict\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datasets import load_metric\n"
      ],
      "metadata": {
        "id": "Sy9zlEPpi-d0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Specify the path to your CSV file\n",
        "file_path = '/content/etiketli_veri.xlsx'\n",
        "\n",
        "# Read the CSV file into a DataFrame\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Display the first few rows of the DataFrame\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2etSoL_i-b_",
        "outputId": "7d59f73e-3e03-4a9f-e253-b6ccffcba57f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                            Metinler  \\\n",
            "0  Telefon kullanmaya başladığımdan beri Turkcell...   \n",
            "1  Turkcell hat iptal \\nhenüz bir saat olmadı Tur...   \n",
            "2  Uzun yıllardır Turkcell Faturalı hat kullanıcı...   \n",
            "3  Turkcell hattımın paketini yeniledim ve 2 aylı...   \n",
            "4  Bilgim olmadan abonelik yaptırılıp faturama ek...   \n",
            "\n",
            "                               sentiment  \n",
            "0  Negative - Pricing and Package Issues  \n",
            "1              Negative - Service Issues  \n",
            "2  Negative - Pricing and Package Issues  \n",
            "3  Negative - Pricing and Package Issues  \n",
            "4                                Neutral  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter and sample 2000 rows for each sentiment category\n",
        "df_positive = df[df['sentiment'] == 'Positive'].sample(n=305, random_state=42)\n",
        "df_Pricing = df[df['sentiment'] == 'Negative - Pricing and Package Issues'].sample(n=305, random_state=42)\n",
        "df_Service = df[df['sentiment'] == 'Negative - Service Issues'].sample(n=305, random_state=42)\n",
        "df_neutral = df[df['sentiment'] == 'Neutral'].sample(n=305, random_state=42)\n",
        "\n",
        "# Combine the sampled DataFrames\n",
        "df_sampled = pd.concat([df_positive, df_Pricing,df_Service, df_neutral])\n",
        "\n",
        "# Shuffle the combined DataFrame (optional)\n",
        "df_sampled = df_sampled.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Save the new DataFrame to a CSV file\n",
        "df_sampled.to_csv('/content/sampled_etiket.csv', index=False)\n",
        "\n",
        "# Display the first few rows of the new DataFrame\n",
        "print(df_sampled.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-szccL2kjCRe",
        "outputId": "6d7bf588-9d32-4a6c-b82c-328353240e90"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                            Metinler  \\\n",
            "0  Turkcell'e numara taşıma yöntemi ile geçiş yap...   \n",
            "1  Güne @TurkTelekom dan kurtulup, @Turkcell e ge...   \n",
            "2  @Turkcell kurulduğundan beri abonesiyim hiç de...   \n",
            "3  Turkcell müşteri hizmetleri ile bağlantı kurar...   \n",
            "4  Turkcell internet paketim dolmadan hızım inanı...   \n",
            "\n",
            "                               sentiment  \n",
            "0  Negative - Pricing and Package Issues  \n",
            "1                               Positive  \n",
            "2                               Positive  \n",
            "3                                Neutral  \n",
            "4              Negative - Service Issues  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "FEH_5qZUGDdB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVK7heLuGFiH",
        "outputId": "e3eeb6cb-104b-4760-b44d-392ba3b17fcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from datasets import load_metric"
      ],
      "metadata": {
        "id": "GaMqrNSMEm94"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(p):\n",
        "    preds = p.predictions.argmax(-1)\n",
        "    labels = p.label_ids\n",
        "\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
        "    accuracy = accuracy_score(labels, preds)\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }"
      ],
      "metadata": {
        "id": "9NUzVvnLEkoe"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Assuming you have your DataFrame (df)\n",
        "# Example: df = pd.read_csv('your_dataset.csv')\n",
        "\n",
        "# Convert the DataFrame to a Dataset object\n",
        "dataset = Dataset.from_pandas(df_sampled)\n",
        "\n",
        "# Define the label mappings for 4 classes\n",
        "label2id = {\n",
        "    \"Positive\": 0,\n",
        "    \"Neutral\": 1,\n",
        "    \"Negative - Service Issues\": 2,\n",
        "    \"Negative - Pricing and Package Issues\": 3\n",
        "}\n",
        "id2label = {v: k for k, v in label2id.items()}\n",
        "\n",
        "# Map the labels in the Dataset\n",
        "dataset = dataset.map(lambda examples: {'label': label2id[examples['sentiment']]})\n",
        "\n",
        "# Now your dataset has integer labels instead of text labels\n",
        "df_converted = dataset.to_pandas()\n",
        "\n",
        "# Split the DataFrame into train and test sets\n",
        "train_df, test_df = train_test_split(df_converted, test_size=0.2, stratify=df_converted['label'])\n",
        "\n",
        "# Convert pandas DataFrames to Hugging Face Dataset objects\n",
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "test_dataset = Dataset.from_pandas(test_df)\n",
        "\n",
        "# Initialize the tokenizer\n",
        "model_name = \"savasy/bert-base-turkish-sentiment-cased\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Load the pre-trained model and adjust for 4 classes\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=4,  # Set the number of output labels to 4\n",
        "    ignore_mismatched_sizes=True  # Handle the size mismatch error\n",
        ")\n",
        "\n",
        "# Update model config with label mappings\n",
        "model.config.label2id = label2id\n",
        "model.config.id2label = id2label\n",
        "\n",
        "# Tokenize the data\n",
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples['Metinler'], padding='max_length', truncation=True)\n",
        "\n",
        "encoded_train_dataset = train_dataset.map(preprocess_function, batched=True)\n",
        "encoded_test_dataset = test_dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    evaluation_strategy='epoch',\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=8,\n",
        "    weight_decay=0.01,\n",
        ")\n",
        "\n",
        "# Initialize Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=encoded_train_dataset,\n",
        "    eval_dataset=encoded_test_dataset,\n",
        "    #compute_metrics=lambda p: load_metric('accuracy').compute(predictions=p.predictions.argmax(-1), references=p.label_ids)\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "# Fine-tune the model\n",
        "trainer.train()\n",
        "\n",
        "# Save the model\n",
        "model.save_pretrained('./fine-tuned-model')\n",
        "tokenizer.save_pretrained('./fine-tuned-model')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 596,
          "referenced_widgets": [
            "2fa5a12614de4ad8a081cb4a1e4d0c86",
            "c0a28b0a2f2a4dfbbdadbd1cabbf33f6",
            "1acd101cc2fd46748172b8071f715356",
            "afcabd683b9d4f77a0ae1f8157cd5b7d",
            "6bde2b5e1c784e91987ba9674e357946",
            "102cd98a8a964c19aa3ec141521cf84b",
            "85719c1193924a2d972a5bf943de43f4",
            "95eeddf2c1ac465e83606d8728309205",
            "30b544117f6248cda997bd577d16de97",
            "c9d3c05a67db4d058db153c1e804218b",
            "adbfdfcb30294fee8b2a765a024ca952",
            "d61bd7ffa5b14486aa1fa4220cc69d3b",
            "1ba463bf8d9a46ce95fb04cfae9ba31d",
            "9449ec15fcea4a139dc51a77f0c313f3",
            "00cbba8bb5ab4edaab14dab239d4fbf5",
            "abb7014193704f12aac6825f56a352d3",
            "393efa2bd4b8425ca0c5f3c2f4f548c3",
            "c36c106ed2504ec789f320bde7153fa7",
            "0dddb8e6930f473daae0b39f25bfd03a",
            "6aee9e54b21f43089ba94966ae949f1a",
            "48c7b2a7155a47299f963d40fe6ea7ab",
            "bc2b41d8c63d42339d0aff8a52f6c970",
            "399897962391495c9b5c239387c769f7",
            "0c9010f38b934d93a47a54866e99ea07",
            "7a46c99f850f43cb9ed017f902f29faf",
            "d0ecd4c9ee844bf6955f12a17d972702",
            "db3ea6aadfa44c76a614c79bdba0f28d",
            "37e9dbeaf7a84b9e806715bf0f026ea3",
            "97f60754e5f24d40a07a2bf3ed5fd913",
            "3ffd8b37d28649e6a14abc80e797755d",
            "79fe4fd87c6d4596889a53570f407375",
            "b6a707749c8e42b7a49ee58aa39caca0",
            "23af7964473f435fb20fd6e35d59794c"
          ]
        },
        "id": "sUs454J-jCP1",
        "outputId": "25e890e0-c032-4a2f-a55e-ea5d388f5e15"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1220 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2fa5a12614de4ad8a081cb4a1e4d0c86"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at savasy/bert-base-turkish-sentiment-cased and are newly initialized because the shapes did not match:\n",
            "- classifier.bias: found shape torch.Size([2]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
            "- classifier.weight: found shape torch.Size([2, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/976 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d61bd7ffa5b14486aa1fa4220cc69d3b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/244 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "399897962391495c9b5c239387c769f7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='976' max='976' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [976/976 13:56, Epoch 8/8]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.369191</td>\n",
              "      <td>0.860656</td>\n",
              "      <td>0.861970</td>\n",
              "      <td>0.880336</td>\n",
              "      <td>0.860656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.315721</td>\n",
              "      <td>0.877049</td>\n",
              "      <td>0.876826</td>\n",
              "      <td>0.883036</td>\n",
              "      <td>0.877049</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.393789</td>\n",
              "      <td>0.889344</td>\n",
              "      <td>0.890040</td>\n",
              "      <td>0.897971</td>\n",
              "      <td>0.889344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.439330</td>\n",
              "      <td>0.881148</td>\n",
              "      <td>0.881162</td>\n",
              "      <td>0.889549</td>\n",
              "      <td>0.881148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.295100</td>\n",
              "      <td>0.421187</td>\n",
              "      <td>0.897541</td>\n",
              "      <td>0.897579</td>\n",
              "      <td>0.901114</td>\n",
              "      <td>0.897541</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.295100</td>\n",
              "      <td>0.475664</td>\n",
              "      <td>0.893443</td>\n",
              "      <td>0.893714</td>\n",
              "      <td>0.899482</td>\n",
              "      <td>0.893443</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.295100</td>\n",
              "      <td>0.513364</td>\n",
              "      <td>0.893443</td>\n",
              "      <td>0.893714</td>\n",
              "      <td>0.899482</td>\n",
              "      <td>0.893443</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.295100</td>\n",
              "      <td>0.517168</td>\n",
              "      <td>0.897541</td>\n",
              "      <td>0.897793</td>\n",
              "      <td>0.904022</td>\n",
              "      <td>0.897541</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./fine-tuned-model/tokenizer_config.json',\n",
              " './fine-tuned-model/special_tokens_map.json',\n",
              " './fine-tuned-model/vocab.txt',\n",
              " './fine-tuned-model/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TuFTqdnADvmQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HhiaHoeTjCNe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A-RSu9dJjCLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Excel dosyasının yolunu belirtin\n",
        "excel_dosyasi = \"/content/deneme.xlsx\"\n",
        "\n",
        "# Excel dosyasını okuyup DataFrame'e dönüştürmek\n",
        "df = pd.read_excel(excel_dosyasi)\n",
        "\n",
        "# DataFrame'i görüntülemek için\n",
        "print(df.head())\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 687
        },
        "id": "VjRYxeDNjCJS",
        "outputId": "6f0891a1-996c-4438-90db-3f6b480e0457"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                            Metinler\n",
            "0  Platinum müşteri hizmetleri oldukça ilgili ve ...\n",
            "1  turkcell superonline firması taşındığım yere i...\n",
            "2  turkcell ’ in star 10 gb paketini kullanmaktay...\n",
            "3  turkcell kullanmadığım aktif olmayan eski hatt...\n",
            "4  turkcell ev internetini 1 yıldır doğru dürüst ...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             Metinler\n",
              "0   Platinum müşteri hizmetleri oldukça ilgili ve ...\n",
              "1   turkcell superonline firması taşındığım yere i...\n",
              "2   turkcell ’ in star 10 gb paketini kullanmaktay...\n",
              "3   turkcell kullanmadığım aktif olmayan eski hatt...\n",
              "4   turkcell ev internetini 1 yıldır doğru dürüst ...\n",
              "5   turkcell internet paketim kendiliğinden bitiyo...\n",
              "6   2024 şubat ayında almış olduğum askercell hatt...\n",
              "7   temmuz ayında hattıma tanımlanan yurt dışı pak...\n",
              "8   gnç uygulamasından çatlat yaptım 9 saatlik int...\n",
              "9   turkcell hattımın 2 yıllık taahhüdü şükür bitt...\n",
              "10  Turkcell'in müşteri hizmetleri hızlı ve etkili...\n",
              "11  Fiber 100mb SuperOnline kullanıcısıyım yaklaşı...\n",
              "12  TurkcellHizmet ya vereceğiniz hizmeti... ya bi...\n",
              "13  Turkcell'in sunduğu hızlı internet hizmeti ve ...\n",
              "14  Turkcell’in Paycell ödeme sistemi çok kullanış...\n",
              "15  Turkcell’in BiP uygulaması ile sevdiklerimle k...\n",
              "16  Turkcell'in Superbox internet hizmeti kesintis..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f00c6d60-149e-49d6-9e94-dc933b42acfd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Metinler</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Platinum müşteri hizmetleri oldukça ilgili ve ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>turkcell superonline firması taşındığım yere i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>turkcell ’ in star 10 gb paketini kullanmaktay...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>turkcell kullanmadığım aktif olmayan eski hatt...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>turkcell ev internetini 1 yıldır doğru dürüst ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>turkcell internet paketim kendiliğinden bitiyo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2024 şubat ayında almış olduğum askercell hatt...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>temmuz ayında hattıma tanımlanan yurt dışı pak...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>gnç uygulamasından çatlat yaptım 9 saatlik int...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>turkcell hattımın 2 yıllık taahhüdü şükür bitt...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Turkcell'in müşteri hizmetleri hızlı ve etkili...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Fiber 100mb SuperOnline kullanıcısıyım yaklaşı...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>TurkcellHizmet ya vereceğiniz hizmeti... ya bi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Turkcell'in sunduğu hızlı internet hizmeti ve ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Turkcell’in Paycell ödeme sistemi çok kullanış...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Turkcell’in BiP uygulaması ile sevdiklerimle k...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Turkcell'in Superbox internet hizmeti kesintis...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f00c6d60-149e-49d6-9e94-dc933b42acfd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f00c6d60-149e-49d6-9e94-dc933b42acfd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f00c6d60-149e-49d6-9e94-dc933b42acfd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-39b11f99-69cd-46a9-85cd-dd386ba3e20b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-39b11f99-69cd-46a9-85cd-dd386ba3e20b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-39b11f99-69cd-46a9-85cd-dd386ba3e20b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_4f4f741e-71c6-4975-a6e2-c4b928be988f\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_4f4f741e-71c6-4975-a6e2-c4b928be988f button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 17,\n  \"fields\": [\n    {\n      \"column\": \"Metinler\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 17,\n        \"samples\": [\n          \"Platinum m\\u00fc\\u015fteri hizmetleri olduk\\u00e7a ilgili ve h\\u0131zl\\u0131 \\u00e7\\u00f6z\\u00fcm sunuyor, fakat Paycell kullan\\u0131rken bazen \\u00f6deme i\\u015flemlerinde gecikmelerle kar\\u015f\\u0131la\\u015f\\u0131yorum.\",\n          \"turkcell superonline firmas\\u0131 ta\\u015f\\u0131nd\\u0131\\u011f\\u0131m yere internet hizmeti sunamad\\u0131\\u011f\\u0131 cayma bedeli olmaks\\u0131z\\u0131n aboneli\\u011fimi iptal edece\\u011fini belirterek benden adrese ta\\u015f\\u0131nd\\u0131\\u011f\\u0131m\\u0131 ikametgah belgesi herhangi bir fatura belgelememi istedi ben ad\\u0131ma olan aboneli\\u011fi kendi edevletimden ald\\u0131\\u011f\\u0131m karekod do\\u011frulamal\\u0131 ikametgah belgesi belgelememe ra\\u011fmen benden \\u0131srarla ba\\u015fka altyap\\u0131 faturas\\u0131 s\\u00f6zle\\u015fme vb belge olmadan iptal yap\\u0131lmayaca\\u011f\\u0131n\\u0131 ifade ediyor vermedi\\u011fi hizmet aboneli\\u011fimi iptal etmeyen turkcellden ikametgah belgesi d\\u0131\\u015f\\u0131nda ba\\u015fka altyap\\u0131 \\u015firketi faturas\\u0131n\\u0131n hangi mevzuata g\\u00f6re istedi\\u011fini ispat etmesini istiyorum kald\\u0131 ikametgah belgesi tam i\\u015fe yar\\u0131yorken aboneli\\u011fimi iptal etmedi\\u011fini a\\u00e7\\u0131klamas\\u0131n\\u0131 istiyorum\",\n          \"turkcell internet paketim kendili\\u011finden bitiyor telefonumu de\\u011fi\\u015fmeme ra\\u011fmen telefonumu kullan\\u0131m al\\u0131\\u015fkanl\\u0131\\u011f\\u0131m\\u0131 de\\u011fi\\u015ftirmeme ra\\u011fmen 2 ay \\u00f6nce platinum paketini y\\u00fckselttikten sonra internetim kendili\\u011finden gidiyor konu alakal\\u0131 m\\u00fc\\u015fteri hizmetlerini aramama ra\\u011fmen \\u00e7\\u00f6z\\u00fcm bulmak yerine kullanm\\u0131\\u015fs\\u0131n\\u0131z denildi kan\\u0131t olarak ekran kayd\\u0131n\\u0131 payla\\u015f\\u0131yorum safariden yakla\\u015f\\u0131k 30dk i\\u00e7erisinde 8gb internet kullan\\u0131lm\\u0131\\u015f g\\u00f6r\\u00fcnmektedir bahse konu olan saatlerde safari uygulamas\\u0131 kapal\\u0131 olmas\\u0131na ra\\u011fmen ayr\\u0131ca teknik olarak ta kadar internetin bitmesinin m\\u00fcmk\\u00fcn olmayaca\\u011f\\u0131 sonucuna eri\\u015ftim turkcell ma\\u011fduriyet gidermek yerine farkl\\u0131 operat\\u00f6rlere ge\\u00e7mem \\u00fcst\\u00fc kapal\\u0131 a\\u00e7\\u0131klama yapt\\u0131m ekran foto\\u011fraf\\u0131ndan anla\\u015f\\u0131laca\\u011f\\u0131 \\u00fczere 29072024 tarihinde yakla\\u015f\\u0131k 16gb internet kullanm\\u0131\\u015f\\u0131m g\\u00f6r\\u00fcnmekte\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install TurkishStemmer\n",
        "!pip install nltk\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4LmX8YPikoGP",
        "outputId": "45fed014-6a02-4795-e72a-ca546fbcede9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting TurkishStemmer\n",
            "  Downloading TurkishStemmer-1.3-py3-none-any.whl.metadata (10 kB)\n",
            "Downloading TurkishStemmer-1.3-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: TurkishStemmer\n",
            "Successfully installed TurkishStemmer-1.3\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from TurkishStemmer import TurkishStemmer\n",
        "from transformers import pipeline\n",
        "\n",
        "stop_words = set(stopwords.words('turkish'))\n",
        "\n",
        "# Türkçe kök bulucu\n",
        "stemmer = TurkishStemmer()\n"
      ],
      "metadata": {
        "id": "9kQXFu4PkoEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ChR2cpISkoCM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def preprocess_text(text):\n",
        "    # Küçük harfe dönüştürme\n",
        "    text = text.lower()\n",
        "\n",
        "    # Noktalama işaretleri ve özel karakterlerin kaldırılması\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "\n",
        "    # Sayıların kaldırılması\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "\n",
        "    # Stop words (durdurma kelimeleri) kaldırma\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "\n",
        "    # Kök bulma (stemming)\n",
        "    tokens = [stemmer.stem(word) for word in tokens]\n",
        "\n",
        "    # Kelimeleri tekrar birleştirme\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "\n",
        "# Metinlere ön işleme adımlarını uygulama\n",
        "df['cleaned_text'] = df['Metinler'].apply(preprocess_text)\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhiIjvK5kn_-",
        "outputId": "07bb0712-9736-41e3-8ea2-0db5b1c4be35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                             Metinler  \\\n",
            "0   Platinum müşteri hizmetleri oldukça ilgili ve ...   \n",
            "1   turkcell superonline firması taşındığım yere i...   \n",
            "2   turkcell ’ in star 10 gb paketini kullanmaktay...   \n",
            "3   turkcell kullanmadığım aktif olmayan eski hatt...   \n",
            "4   turkcell ev internetini 1 yıldır doğru dürüst ...   \n",
            "5   turkcell internet paketim kendiliğinden bitiyo...   \n",
            "6   2024 şubat ayında almış olduğum askercell hatt...   \n",
            "7   temmuz ayında hattıma tanımlanan yurt dışı pak...   \n",
            "8   gnç uygulamasından çatlat yaptım 9 saatlik int...   \n",
            "9   turkcell hattımın 2 yıllık taahhüdü şükür bitt...   \n",
            "10  Turkcell'in müşteri hizmetleri hızlı ve etkili...   \n",
            "11  Fiber 100mb SuperOnline kullanıcısıyım yaklaşı...   \n",
            "12  TurkcellHizmet ya vereceğiniz hizmeti... ya bi...   \n",
            "13  Turkcell'in sunduğu hızlı internet hizmeti ve ...   \n",
            "14  Turkcell’in Paycell ödeme sistemi çok kullanış...   \n",
            "15  Turkcell’in BiP uygulaması ile sevdiklerimle k...   \n",
            "16  Turkcell'in Superbox internet hizmeti kesintis...   \n",
            "\n",
            "                                         cleaned_text  \n",
            "0   platinum müşter hizmet oldukç ilgi hızl çöz su...  \n",
            "1   turkcell superonlin firma taşındık yer interne...  \n",
            "2   turkcell in star gb paket kullanmak paket içer...  \n",
            "3   turkcell kullanmadık aktif olmayan esk hatt sü...  \n",
            "4   turkcell ev internet yıl doğr dürüst kullanamı...  \n",
            "5   turkcell internet pake kendilik bitiyor telefo...  \n",
            "6   şubat ayın al olduk askercell hatt mart ayın a...  \n",
            "7   temmuz ayın hatt tanımlanan yurt dış pake yurt...  \n",
            "8   gnç uygulama çatlat yapt saatlik internet gelt...  \n",
            "9   turkcell hatt yıllık taahhü şükür bitt hatt ip...  \n",
            "10  turkcell müşter hizmet hızl etkilipaycelln ürü...  \n",
            "11  fiber mb superonlin kullanıcı yaklaşık haf twi...  \n",
            "12  turkcellhizmet verecek hizm bilader allah adas...  \n",
            "13  turkcell sunduk hızl internet hizm müşter dest...  \n",
            "14  turkcell paycell ödem siste kullanış aynı zama...  \n",
            "15  turkcell bip uygulama sevdik kolay iletiş kura...  \n",
            "16  turkcell superbox internet hizm kesintis çalış...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import json\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "\n",
        "# Load the fine-tuned sentiment model and tokenizer\n",
        "model_path = '/content/fine-tuned-model'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "\n",
        "# Initialize the sentiment analysis pipeline with the fine-tuned model\n",
        "sentiment_model = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "# NER model loading\n",
        "ner_model = pipeline(\"ner\", model=\"savasy/bert-base-turkish-ner-cased\")\n",
        "\n",
        "def combine_subwords(entities):\n",
        "    combined_entities = []\n",
        "    current_entity = \"\"\n",
        "\n",
        "    for entity in entities:\n",
        "        if entity['entity'].startswith('B-') or entity['entity'].startswith('I-'):\n",
        "            if entity['entity'] in ['B-ORG', 'I-ORG']:\n",
        "                if entity['word'].startswith('##'):\n",
        "                    current_entity += entity['word'].replace('##', '')\n",
        "                else:\n",
        "                    if current_entity:\n",
        "                        combined_entities.append(current_entity)\n",
        "                        current_entity = \"\"\n",
        "                    current_entity = entity['word']\n",
        "\n",
        "    if current_entity:\n",
        "        combined_entities.append(current_entity)\n",
        "\n",
        "    combined_entities = list(set(combined_entities))\n",
        "\n",
        "    return combined_entities\n",
        "\n",
        "def analyze_entity_sentiment(text, entities):\n",
        "    results = []\n",
        "    for entity in entities:\n",
        "        entity_index = text.find(entity)\n",
        "        if entity_index != -1:\n",
        "            sentiment = sentiment_model(text)\n",
        "            results.append({\n",
        "                \"entity\": entity,\n",
        "                \"sentiment\": sentiment[0]['label']\n",
        "            })\n",
        "    return results\n",
        "\n",
        "def analyze_text(text):\n",
        "    # Entity extraction\n",
        "    entities = ner_model(text)\n",
        "\n",
        "    # Combine subword tokens and filter for ORGANISATION entities\n",
        "    combined_entities = combine_subwords(entities)\n",
        "\n",
        "    # Analyze sentiment for each entity\n",
        "    results = analyze_entity_sentiment(text, combined_entities)\n",
        "\n",
        "    return results\n",
        "\n",
        "def format_analysis(text, analysis):\n",
        "    entity_list = list(set([item['entity'] for item in analysis if len(item['entity']) > 2]))\n",
        "    results = [{'entity': item['entity'], 'sentiment': item['sentiment']} for item in analysis if len(item['entity']) > 2]\n",
        "    return {\n",
        "        'text': text,\n",
        "        'results': results\n",
        "    }\n",
        "\n",
        "def save_to_json(df, filename):\n",
        "    with open(filename, 'w', encoding='utf-8') as f:\n",
        "        for _, row in df.iterrows():\n",
        "            original_text = row['Metinler']  # Use 'cleaned_text' as per your DataFrame\n",
        "            analysis = format_analysis(original_text, row['analysis'])\n",
        "            json.dump(analysis, f, ensure_ascii=False, indent=4)\n",
        "            f.write('\\n')\n",
        "\n",
        "\n",
        "# DataFrame analysis\n",
        "df['analysis'] = df['cleaned_text'].apply(analyze_text)\n",
        "\n",
        "# Save results to a JSON file\n",
        "save_to_json(df, 'analysis_results.json')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OygS_ZOWkyXP",
        "outputId": "31f5e463-a227-490f-e77d-36b4e790b271"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
            "Some weights of the model checkpoint at savasy/bert-base-turkish-ner-cased were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YnLqv6ZBk92N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# 'folder_name' klasörünü zip dosyasına dönüştürmek\n",
        "shutil.make_archive('fine-tuned-model', 'zip', 'fine-tuned-model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "hJdy8jgLu8bS",
        "outputId": "397be498-eca8-4318-f72c-31fb9840643d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/fine-tuned-model.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "shutil.make_archive('/content/fine-tuned-model', 'zip', '/content/fine-tuned-model')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "lyOSSZ298Uz-",
        "outputId": "0a46b102-e77d-4297-dc41-a2f29d1dab21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/fine-tuned-model.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('/content/fine-tuned-model.zip')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "XNTjhUBh6wnb",
        "outputId": "065746fd-d0a3-4985-f23c-0496045b2f21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_be18ea40-4480-41bf-a957-692acbf9e689\", \"fine-tuned-model.zip\", 410965048)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QsCBjGIR6wlr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import json\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "\n",
        "# Load the fine-tuned sentiment model and tokenizer\n",
        "model_path = '/content/fine-tuned-model'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "\n",
        "# Initialize the sentiment analysis pipeline with the fine-tuned model\n",
        "sentiment_model = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "# NER model loading\n",
        "ner_model = pipeline(\"ner\", model=\"savasy/bert-base-turkish-ner-cased\")\n",
        "\n",
        "def combine_subwords(entities):\n",
        "    combined_entities = []\n",
        "    current_entity = \"\"\n",
        "\n",
        "    for entity in entities:\n",
        "        if entity['entity'].startswith('B-') or entity['entity'].startswith('I-'):\n",
        "            if entity['entity'] in ['B-ORG', 'I-ORG']:\n",
        "                if entity['word'].startswith('##'):\n",
        "                    current_entity += entity['word'].replace('##', '')\n",
        "                else:\n",
        "                    if current_entity:\n",
        "                        combined_entities.append(current_entity)\n",
        "                        current_entity = \"\"\n",
        "                    current_entity = entity['word']\n",
        "\n",
        "    if current_entity:\n",
        "        combined_entities.append(current_entity)\n",
        "\n",
        "    combined_entities = list(set(combined_entities))\n",
        "\n",
        "    return combined_entities\n",
        "\n",
        "def analyze_entity_sentiment(text, entities, window_size=10):\n",
        "    results = []\n",
        "    words = text.split()\n",
        "\n",
        "    for entity in entities:\n",
        "        entity_indices = [i for i, word in enumerate(words) if entity in word]\n",
        "        for index in entity_indices:\n",
        "            # Get context window around the entity\n",
        "            start = max(0, index - window_size)\n",
        "            end = min(len(words), index + window_size + 1)\n",
        "            context = \" \".join(words[start:end])\n",
        "\n",
        "            # Perform sentiment analysis on the context\n",
        "            sentiment = sentiment_model(context)\n",
        "            results.append({\n",
        "                \"entity\": entity,\n",
        "                \"sentiment\": sentiment[0]['label'],\n",
        "                \"context\": context\n",
        "            })\n",
        "    return results\n",
        "\n",
        "def analyze_text(text):\n",
        "    # Entity extraction\n",
        "    entities = ner_model(text)\n",
        "\n",
        "    # Combine subword tokens and filter for ORGANISATION entities\n",
        "    combined_entities = combine_subwords(entities)\n",
        "\n",
        "    # Analyze sentiment for each entity with its surrounding context\n",
        "    results = analyze_entity_sentiment(text, combined_entities)\n",
        "\n",
        "    return results\n",
        "\n",
        "def format_analysis(text, analysis):\n",
        "    entity_list = list(set([item['entity'] for item in analysis if len(item['entity']) > 2]))\n",
        "    results = [{'entity': item['entity'], 'sentiment': item['sentiment']} for item in analysis if len(item['entity']) > 2]\n",
        "    return {\n",
        "        'text': text,\n",
        "        'results': results\n",
        "    }\n",
        "\n",
        "def save_to_json(df, filename):\n",
        "    with open(filename, 'w', encoding='utf-8') as f:\n",
        "        for _, row in df.iterrows():\n",
        "            original_text = row['Metinler']  # Use 'cleaned_text' as per your DataFrame\n",
        "            analysis = format_analysis(original_text, row['analysis'])\n",
        "            json.dump(analysis, f, ensure_ascii=False, indent=4)\n",
        "            f.write('\\n')\n",
        "\n",
        "\n",
        "# DataFrame analysis\n",
        "df['analysis'] = df['cleaned_text'].apply(analyze_text)\n",
        "\n",
        "# Save results to a JSON file\n",
        "save_to_json(df, 'analysis_results2.json')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EaQxNdgl6wja",
        "outputId": "6a881cb9-41d6-4603-ff46-33bd40cf3f8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
            "Some weights of the model checkpoint at savasy/bert-base-turkish-ner-cased were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import json\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "\n",
        "# Load the fine-tuned sentiment model and tokenizer\n",
        "model_path = '/content/fine-tuned-model'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "\n",
        "# Initialize the sentiment analysis pipeline with the fine-tuned model\n",
        "sentiment_model = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "# NER model loading\n",
        "ner_model = pipeline(\"ner\", model=\"savasy/bert-base-turkish-ner-cased\")\n",
        "\n",
        "def combine_subwords(entities):\n",
        "    combined_entities = []\n",
        "    current_entity = \"\"\n",
        "\n",
        "    for entity in entities:\n",
        "        if entity['entity'].startswith('B-') or entity['entity'].startswith('I-'):\n",
        "            if entity['entity'] in ['B-ORG', 'I-ORG']:\n",
        "                if entity['word'].startswith('##'):\n",
        "                    current_entity += entity['word'].replace('##', '')\n",
        "                else:\n",
        "                    if current_entity:\n",
        "                        combined_entities.append(current_entity)\n",
        "                        current_entity = \"\"\n",
        "                    current_entity = entity['word']\n",
        "\n",
        "    if current_entity:\n",
        "        combined_entities.append(current_entity)\n",
        "\n",
        "    combined_entities = list(set(combined_entities))\n",
        "\n",
        "    return combined_entities\n",
        "\n",
        "def analyze_entity_sentiment(text, entities):\n",
        "    results = []\n",
        "    sentences = re.split(r'(?<=[.!?]) +', text)\n",
        "    for entity in entities:\n",
        "        for sentence in sentences:\n",
        "            if entity in sentence:\n",
        "                sentiment = sentiment_model(sentence)\n",
        "                results.append({\n",
        "                    \"entity\": entity,\n",
        "                    \"sentiment\": sentiment[0]['label'],\n",
        "                    \"sentence\": sentence\n",
        "                })\n",
        "                break  # Move to the next entity after finding the relevant sentence\n",
        "    return results\n",
        "\n",
        "def analyze_text(text):\n",
        "    # Entity extraction\n",
        "    entities = ner_model(text)\n",
        "\n",
        "    # Combine subword tokens and filter for ORGANISATION entities\n",
        "    combined_entities = combine_subwords(entities)\n",
        "\n",
        "    # Analyze sentiment for each entity\n",
        "    results = analyze_entity_sentiment(text, combined_entities)\n",
        "\n",
        "    return results\n",
        "\n",
        "def format_analysis(text, analysis):\n",
        "    entity_list = list(set([item['entity'] for item in analysis if len(item['entity']) > 2]))\n",
        "    results = [{'entity': item['entity'], 'sentiment': item['sentiment'], 'sentence': item['sentence']} for item in analysis if len(item['entity']) > 2]\n",
        "    return {\n",
        "        'text': text,\n",
        "        'results': results\n",
        "    }\n",
        "\n",
        "def save_to_json(df, filename):\n",
        "    with open(filename, 'w', encoding='utf-8') as f:\n",
        "        for _, row in df.iterrows():\n",
        "            original_text = row['Metinler']  # Use 'cleaned_text' as per your DataFrame\n",
        "            analysis = format_analysis(original_text, row['analysis'])\n",
        "            json.dump(analysis, f, ensure_ascii=False, indent=4)\n",
        "            f.write('\\n')\n",
        "\n",
        "\n",
        "\n",
        "# DataFrame analysis\n",
        "df['analysis'] = df['cleaned_text'].apply(analyze_text)\n",
        "\n",
        "# Save results to a JSON file\n",
        "save_to_json(df, 'analysis_results3.json')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7aLELWYtE_vy",
        "outputId": "14de54b3-a0de-4dfc-f017-1404169480c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
            "Some weights of the model checkpoint at savasy/bert-base-turkish-ner-cased were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import json\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "\n",
        "# Load the fine-tuned sentiment model and tokenizer\n",
        "model_path = '/content/fine-tuned-model'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "\n",
        "# Check if GPU is available and set the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Initialize the sentiment analysis pipeline with the fine-tuned model\n",
        "sentiment_model = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer, device=0 if device.type == 'cuda' else -1)\n",
        "\n",
        "# NER model loading\n",
        "ner_model = pipeline(\"ner\", model=\"savasy/bert-base-turkish-ner-cased\", device=0 if device.type == 'cuda' else -1)\n",
        "\n",
        "def combine_subwords(entities):\n",
        "    combined_entities = []\n",
        "    current_entity = \"\"\n",
        "\n",
        "    for entity in entities:\n",
        "        if entity['entity'].startswith('B-') or entity['entity'].startswith('I-'):\n",
        "            if entity['entity'] in ['B-ORG', 'I-ORG']:\n",
        "                if entity['word'].startswith('##'):\n",
        "                    current_entity += entity['word'].replace('##', '')\n",
        "                else:\n",
        "                    if current_entity:\n",
        "                        combined_entities.append(current_entity)\n",
        "                        current_entity = \"\"\n",
        "                    current_entity = entity['word']\n",
        "\n",
        "    if current_entity:\n",
        "        combined_entities.append(current_entity)\n",
        "\n",
        "    combined_entities = list(set(combined_entities))\n",
        "\n",
        "    return combined_entities\n",
        "\n",
        "def analyze_entity_sentiment(text, entities):\n",
        "    results = []\n",
        "    sentences = re.split(r'(?<=[.!?]) +', text)  # Split text into sentences\n",
        "    for entity in entities:\n",
        "        for sentence in sentences:\n",
        "            if entity in sentence:\n",
        "                sentiment = sentiment_model(sentence)\n",
        "                results.append({\n",
        "                    \"entity\": entity,\n",
        "                    \"sentiment\": sentiment[0]['label'],\n",
        "                    \"sentence\": sentence\n",
        "                })\n",
        "                break  # Move to the next entity after finding the relevant sentence\n",
        "    return results\n",
        "\n",
        "def analyze_text(text):\n",
        "    # Entity extraction\n",
        "    entities = ner_model(text)\n",
        "\n",
        "    # Combine subword tokens and filter for ORGANISATION entities\n",
        "    combined_entities = combine_subwords(entities)\n",
        "\n",
        "    # Analyze sentiment for each entity\n",
        "    results = analyze_entity_sentiment(text, combined_entities)\n",
        "\n",
        "    return results\n",
        "\n",
        "def format_analysis(text, analysis):\n",
        "    entity_list = list(set([item['entity'] for item in analysis if len(item['entity']) > 2]))\n",
        "    results = [{'entity': item['entity'], 'sentiment': item['sentiment'], 'sentence': item['sentence']} for item in analysis if len(item['entity']) > 2]\n",
        "    return {\n",
        "        'text': text,\n",
        "        'results': results\n",
        "    }\n",
        "\n",
        "def save_to_json(df, filename):\n",
        "    with open(filename, 'w', encoding='utf-8') as f:\n",
        "        for _, row in df.iterrows():\n",
        "            original_text = row['Metinler']  # Use 'cleaned_text' as per your DataFrame\n",
        "            analysis = format_analysis(original_text, row['analysis'])\n",
        "            json.dump(analysis, f, ensure_ascii=False, indent=4)\n",
        "            f.write('\\n')\n",
        "\n",
        "\n",
        "# DataFrame analysis\n",
        "df['analysis'] = df['cleaned_text'].apply(analyze_text)\n",
        "\n",
        "# Save results to a JSON file\n",
        "save_to_json(df, 'analysis_results4.json')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "SqP40wkFHZ1q",
        "outputId": "6ea3a277-c19c-4a51-d3c0-abcfba44981a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at savasy/bert-base-turkish-ner-cased were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, jsonify\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Modeli ve tokenizer'ı yükleyin\n",
        "model_path = '/content/fine-tuned-model'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    data = request.get_json()\n",
        "    inputs = tokenizer(data['text'], return_tensors='pt')\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    predictions = torch.argmax(outputs.logits, dim=1).tolist()\n",
        "    return jsonify({'predictions': predictions})\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(host='0.0.0.0', port=5000)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from flask import Flask, request, jsonify\n",
        "from flasgger import Swagger\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "\n",
        "app = Flask(__name__)\n",
        "Swagger(app)\n",
        "\n",
        "# Modeli ve tokenizer'ı yükleyin\n",
        "model_path = '/content/fine-tuned-model'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    \"\"\"\n",
        "    Predict the class of a given text\n",
        "    ---\n",
        "    parameters:\n",
        "      - name: text\n",
        "        in: body\n",
        "        type: string\n",
        "        required: true\n",
        "        description: The text to classify\n",
        "    responses:\n",
        "      200:\n",
        "        description: The prediction result\n",
        "        schema:\n",
        "          type: object\n",
        "          properties:\n",
        "            predictions:\n",
        "              type: array\n",
        "              items:\n",
        "                type: integer\n",
        "    \"\"\"\n",
        "    data = request.get_json()\n",
        "    inputs = tokenizer(data['text'], return_tensors='pt')\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    predictions = torch.argmax(outputs.logits, dim=1).tolist()\n",
        "    return jsonify({'predictions': predictions})\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(host='0.0.0.0', port=5000)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        },
        "id": "t96RGYyXOfaO",
        "outputId": "005b8a06-0c02-4329-c465-c5203b8ccb0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on all addresses (0.0.0.0)\n",
            " * Running on http://127.0.0.1:5000\n",
            " * Running on http://172.28.0.12:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'flasgger'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-84-91a4482acfca>\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mflask\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFlask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjsonify\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mflasgger\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSwagger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoModelForSequenceClassification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'flasgger'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jqAsWvxVPXLw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}